{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b97b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Data Configuration\n",
    "DATA_PATH = \"C:\\\\Users\\\\rhrou\\\\Downloads\\\\justice.csv\"\n",
    "TARGET_COLUMN = 'first_party_winner'\n",
    "TEXT_COLUMN = 'facts'\n",
    "\n",
    "# Train-Test Split Configuration\n",
    "TEST_SIZE = 0.25\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# BERT Configuration\n",
    "# Options: 'bert-base-uncased', 'nlpaueb/legal-bert-base-uncased'\n",
    "BERT_MODEL_NAME = 'bert-base-uncased'  \n",
    "\n",
    "BERT_MAX_LENGTH = 512\n",
    "BERT_BATCH_SIZE = 40\n",
    "\n",
    "# Text Preprocessing Configuration\n",
    "LOWERCASE = True  # Set to True for 'uncased' models, False for 'cased' models\n",
    "NORMALIZE_UNICODE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aaf6f4",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea38563a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded: 3288 cases, 17 columns\n",
      "\n",
      "[2/6] Removing missing values...\n",
      "      Retained: 3098 cases (94.2%)\n",
      "\n",
      "[3/6] Preprocessing text data...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(\"data/justice.csv\")\n",
    "df = df.dropna(subset=[\"facts\", \"first_party_winner\"])\n",
    "df[\"label\"] = df[\"first_party_winner\"].astype(int)\n",
    "\n",
    "print(f\"      Loaded: {df.shape[0]} cases, {df.shape[1]} columns\")\n",
    "\n",
    "# 2. Remove Missing Values\n",
    "print(f\"\\n[2/6] Removing missing values...\")\n",
    "initial_count = df.shape[0]\n",
    "df.dropna(inplace=True)\n",
    "print(f\"      Retained: {df.shape[0]} cases ({df.shape[0]/initial_count*100:.1f}%)\")\n",
    "\n",
    "# 4. Extract and Clean Text\n",
    "print(f\"\\n[3/6] Preprocessing text data...\")\n",
    "df_nlp = df[[TEXT_COLUMN]].copy()\n",
    "\n",
    "# Remove HTML tags\n",
    "df['facts'] = df['facts'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "\n",
    "# Apply text preprocessing\n",
    "df_nlp['facts_clean'] = df_nlp[TEXT_COLUMN].apply(\n",
    "    lambda x: preprocess_text(x, lowercase=LOWERCASE, normalize=NORMALIZE_UNICODE))\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"facts\"].tolist(),\n",
    "    df[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751638e",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10f0cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wraps tokenized text and labels so PyTorch's dataloader can batch and feed them to the model during training\n",
    "class JusticeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, model_type=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.model_type = model_type\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "         # DistilBERT and MiniLM don't use token_type_ids\n",
    "        if self.model_type in [\"Step1_DistilBERT\", \"Step4_MiniLM\", \"Step3_TinyBERT\"]:\n",
    "            item.pop(\"token_type_ids\", None)\n",
    "        return item\n",
    "\n",
    "# Compute metrics function    \n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None)\n",
    "    macro_f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_class0\": precision[0],\n",
    "        \"recall_class0\": recall[0],\n",
    "        \"f1_class0\": f1[0],\n",
    "        \"precision_class1\": precision[1],\n",
    "        \"recall_class1\": recall[1],\n",
    "        \"f1_class1\": f1[1],\n",
    "        \"macro_f1\": macro_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4ac824",
   "metadata": {},
   "source": [
    "## Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3ecd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944e26a9",
   "metadata": {},
   "source": [
    "## Define Interpretability Function through Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af1f1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_prediction(model, tokenizer, text, label=None):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # FIX: Move inputs to same device as model\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    if label is None:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            label = outputs.logits.argmax(-1).item()\n",
    "\n",
    "    def forward_func(embeddings, attention_mask=None):\n",
    "        outputs = model(inputs_embeds=embeddings, attention_mask=attention_mask)\n",
    "        return torch.softmax(outputs.logits, dim=1)[:, label]\n",
    "\n",
    "    embeddings = model.get_input_embeddings()(inputs[\"input_ids\"])\n",
    "    ig = IntegratedGradients(forward_func)\n",
    "    attributions, _ = ig.attribute(\n",
    "        embeddings,\n",
    "        additional_forward_args=(inputs[\"attention_mask\"],),\n",
    "        return_convergence_delta=True\n",
    "    )\n",
    "\n",
    "    scores = attributions.sum(dim=-1).squeeze(0).detach().cpu().numpy()  # .cpu() before .numpy()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b06aa",
   "metadata": {},
   "source": [
    "## Model Selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d572aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "model_configs = {\n",
    "    \"Teacher_BERT\": {\n",
    "        \"tokenizer\": \"bert-base-uncased\",\n",
    "        \"model\": lambda: BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "    },\n",
    "    \"Step1_DistilBERT\": {\n",
    "        \"tokenizer\": \"distilbert-base-uncased\",\n",
    "        \"model\": lambda: DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "    },\n",
    "    \"Step3_TinyBERT\": {\n",
    "        \"tokenizer\": \"bert-base-uncased\",\n",
    "        \"model\": lambda: BertForSequenceClassification.from_pretrained(\"huawei-noah/TinyBERT_General_4L_512D\", num_labels=2)\n",
    "    }\n",
    "    # \"Step4_MiniLM\": {\n",
    "    #     \"tokenizer\": \"bert-base-uncased\",\n",
    "    #     \"model\": lambda: BertForSequenceClassification.from_pretrained(\"microsoft/MiniLM-L12-H384-uncased\", num_labels=2)\n",
    "    # } - this one keeps gives the error on token_type_ids not found\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be632c",
   "metadata": {},
   "source": [
    "## Loop through models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b614315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Training Teacher_BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='930' max='930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [930/930 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Class0</th>\n",
       "      <th>Recall Class0</th>\n",
       "      <th>F1 Class0</th>\n",
       "      <th>Precision Class1</th>\n",
       "      <th>Recall Class1</th>\n",
       "      <th>F1 Class1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.641219</td>\n",
       "      <td>0.667742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800774</td>\n",
       "      <td>0.400387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.634657</td>\n",
       "      <td>0.669355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.668821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.801549</td>\n",
       "      <td>0.405605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.602900</td>\n",
       "      <td>0.636075</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.087379</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>0.676420</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.789950</td>\n",
       "      <td>0.468444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Training Step1_DistilBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='930' max='930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [930/930 00:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Class0</th>\n",
       "      <th>Recall Class0</th>\n",
       "      <th>F1 Class0</th>\n",
       "      <th>Precision Class1</th>\n",
       "      <th>Recall Class1</th>\n",
       "      <th>F1 Class1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.610200</td>\n",
       "      <td>0.636517</td>\n",
       "      <td>0.667742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800774</td>\n",
       "      <td>0.400387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.638400</td>\n",
       "      <td>0.644972</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.053398</td>\n",
       "      <td>0.097345</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.798817</td>\n",
       "      <td>0.448081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.579600</td>\n",
       "      <td>0.662350</td>\n",
       "      <td>0.630645</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.160194</td>\n",
       "      <td>0.223729</td>\n",
       "      <td>0.674200</td>\n",
       "      <td>0.864734</td>\n",
       "      <td>0.757672</td>\n",
       "      <td>0.490700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "DistilBertForSequenceClassification.forward() got an unexpected keyword argument 'token_type_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m     teacher_vectors = [explain_prediction(model, tokenizer, text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m val_texts[:\u001b[32m50\u001b[39m]]\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     student_vectors = \u001b[43m[\u001b[49m\u001b[43mexplain_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_texts\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     66\u001b[39m     cos_sims = []\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t_vec, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(teacher_vectors, val_texts[:\u001b[32m50\u001b[39m]):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     63\u001b[39m     teacher_vectors = [explain_prediction(model, tokenizer, text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m val_texts[:\u001b[32m50\u001b[39m]]\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     student_vectors = [\u001b[43mexplain_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m val_texts[:\u001b[32m50\u001b[39m]]\n\u001b[32m     66\u001b[39m     cos_sims = []\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t_vec, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(teacher_vectors, val_texts[:\u001b[32m50\u001b[39m]):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mexplain_prediction\u001b[39m\u001b[34m(model, tokenizer, text, label)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m         label = outputs.logits.argmax(-\u001b[32m1\u001b[39m).item()\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_func\u001b[39m(embeddings, attention_mask=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mTypeError\u001b[39m: DistilBertForSequenceClassification.forward() got an unexpected keyword argument 'token_type_ids'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    BertForSequenceClassification, BertTokenizer, BertConfig,\n",
    "    DistilBertForSequenceClassification, DistilBertTokenizer,\n",
    "    Trainer, TrainingArguments\n",
    ")\n",
    "from captum.attr import IntegratedGradients\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "results = {}\n",
    "teacher_vectors = {}\n",
    "\n",
    "for name, cfg in model_configs.items():\n",
    "    print(f\"\\nüîπ Training {name}...\")\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(cfg[\"tokenizer\"]) if \"bert\" in cfg[\"tokenizer\"] else DistilBertTokenizer.from_pretrained(cfg[\"tokenizer\"])\n",
    "\n",
    "    # FIX: Don't create token_type_ids for DistilBERT\n",
    "    return_token_type_ids = \"distil\" not in cfg[\"tokenizer\"].lower()\n",
    "    \n",
    "    # Tokenize\n",
    "    train_enc = tokenizer(\n",
    "        train_texts, \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=128,\n",
    "        return_token_type_ids=return_token_type_ids  # ‚Üê Add this\n",
    "    )\n",
    "    val_enc = tokenizer(\n",
    "        val_texts, \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=128,\n",
    "        return_token_type_ids=return_token_type_ids  # ‚Üê Add this\n",
    "    )\n",
    "    \n",
    "    train_ds = JusticeDataset(train_enc, train_labels, model_type=name)\n",
    "    val_ds = JusticeDataset(val_enc, val_labels, model_type=name)\n",
    "    # Load model\n",
    "    model = cfg[\"model\"]()\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    results[name] = metrics\n",
    "\n",
    "    # Explanations: only store teacher‚Äôs attributions once\n",
    "    if name == \"Teacher_BERT\":\n",
    "        teacher_vectors = [explain_prediction(model, tokenizer, text) for text in val_texts[:50]]\n",
    "    else:\n",
    "        student_vectors = [explain_prediction(model, tokenizer, text) for text in val_texts[:50]]\n",
    "        cos_sims = []\n",
    "        for t_vec, text in zip(teacher_vectors, val_texts[:50]):\n",
    "            s_vec = explain_prediction(model, tokenizer, text)\n",
    "            sim = cosine_similarity([t_vec], [s_vec])[0][0]\n",
    "            cos_sims.append(sim)\n",
    "        results[name][\"cosine_similarity\"] = np.mean(cos_sims)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
